{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('ai': conda)",
   "metadata": {
    "interpreter": {
     "hash": "5031f79d2a0762a93fe093d47ca4666becb7c86b29dce5af1939a06639a94482"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_extractor import loadFeatureExtractor\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = loadFeatureExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2]               0\n       Bottleneck-48          [-1, 512, 32, 32]               0\n           Conv2d-49          [-1, 128, 32, 32]          65,536\n      BatchNorm2d-50          [-1, 128, 32, 32]             256\n             ReLU-51          [-1, 128, 32, 32]               0\n           Conv2d-52          [-1, 128, 32, 32]         147,456\n      BatchNorm2d-53          [-1, 128, 32, 32]             256\n             ReLU-54          [-1, 128, 32, 32]               0\n           Conv2d-55          [-1, 512, 32, 32]          65,536\n      BatchNorm2d-56          [-1, 512, 32, 32]           1,024\n             ReLU-57          [-1, 512, 32, 32]               0\n       Bottleneck-58          [-1, 512, 32, 32]               0\n           Conv2d-59          [-1, 128, 32, 32]          65,536\n      BatchNorm2d-60          [-1, 128, 32, 32]             256\n             ReLU-61          [-1, 128, 32, 32]               0\n           Conv2d-62          [-1, 128, 32, 32]         147,456\n      BatchNorm2d-63          [-1, 128, 32, 32]             256\n             ReLU-64          [-1, 128, 32, 32]               0\n           Conv2d-65          [-1, 512, 32, 32]          65,536\n      BatchNorm2d-66          [-1, 512, 32, 32]           1,024\n             ReLU-67          [-1, 512, 32, 32]               0\n       Bottleneck-68          [-1, 512, 32, 32]               0\n           Conv2d-69          [-1, 128, 32, 32]          65,536\n      BatchNorm2d-70          [-1, 128, 32, 32]             256\n             ReLU-71          [-1, 128, 32, 32]               0\n           Conv2d-72          [-1, 128, 32, 32]         147,456\n      BatchNorm2d-73          [-1, 128, 32, 32]             256\n             ReLU-74          [-1, 128, 32, 32]               0\n           Conv2d-75          [-1, 512, 32, 32]          65,536\n      BatchNorm2d-76          [-1, 512, 32, 32]           1,024\n             ReLU-77          [-1, 512, 32, 32]               0\n       Bottleneck-78          [-1, 512, 32, 32]               0\n           Conv2d-79          [-1, 256, 32, 32]         131,072\n      BatchNorm2d-80          [-1, 256, 32, 32]             512\n             ReLU-81          [-1, 256, 32, 32]               0\n           Conv2d-82          [-1, 256, 16, 16]         589,824\n      BatchNorm2d-83          [-1, 256, 16, 16]             512\n             ReLU-84          [-1, 256, 16, 16]               0\n           Conv2d-85         [-1, 1024, 16, 16]         262,144\n      BatchNorm2d-86         [-1, 1024, 16, 16]           2,048\n           Conv2d-87         [-1, 1024, 16, 16]         524,288\n      BatchNorm2d-88         [-1, 1024, 16, 16]           2,048\n             ReLU-89         [-1, 1024, 16, 16]               0\n       Bottleneck-90         [-1, 1024, 16, 16]               0\n           Conv2d-91          [-1, 256, 16, 16]         262,144\n      BatchNorm2d-92          [-1, 256, 16, 16]             512\n             ReLU-93          [-1, 256, 16, 16]               0\n           Conv2d-94          [-1, 256, 16, 16]         589,824\n      BatchNorm2d-95          [-1, 256, 16, 16]             512\n             ReLU-96          [-1, 256, 16, 16]               0\n           Conv2d-97         [-1, 1024, 16, 16]         262,144\n      BatchNorm2d-98         [-1, 1024, 16, 16]           2,048\n             ReLU-99         [-1, 1024, 16, 16]               0\n      Bottleneck-100         [-1, 1024, 16, 16]               0\n          Conv2d-101          [-1, 256, 16, 16]         262,144\n     BatchNorm2d-102          [-1, 256, 16, 16]             512\n            ReLU-103          [-1, 256, 16, 16]               0\n          Conv2d-104          [-1, 256, 16, 16]         589,824\n     BatchNorm2d-105          [-1, 256, 16, 16]             512\n            ReLU-106          [-1, 256, 16, 16]               0\n          Conv2d-107         [-1, 1024, 16, 16]         262,144\n     BatchNorm2d-108         [-1, 1024, 16, 16]           2,048\n            ReLU-109         [-1, 1024, 16, 16]               0\n      Bottleneck-110         [-1, 1024, 16, 16]               0\n          Conv2d-111          [-1, 256, 16, 16]         262,144\n     BatchNorm2d-112          [-1, 256, 16, 16]             512\n            ReLU-113          [-1, 256, 16, 16]               0\n          Conv2d-114          [-1, 256, 16, 16]         589,824\n     BatchNorm2d-115          [-1, 256, 16, 16]             512\n            ReLU-116          [-1, 256, 16, 16]               0\n          Conv2d-117         [-1, 1024, 16, 16]         262,144\n     BatchNorm2d-118         [-1, 1024, 16, 16]           2,048\n            ReLU-119         [-1, 1024, 16, 16]               0\n      Bottleneck-120         [-1, 1024, 16, 16]               0\n          Conv2d-121          [-1, 256, 16, 16]         262,144\n     BatchNorm2d-122          [-1, 256, 16, 16]             512\n            ReLU-123          [-1, 256, 16, 16]               0\n          Conv2d-124          [-1, 256, 16, 16]         589,824\n     BatchNorm2d-125          [-1, 256, 16, 16]             512\n            ReLU-126          [-1, 256, 16, 16]               0\n          Conv2d-127         [-1, 1024, 16, 16]         262,144\n     BatchNorm2d-128         [-1, 1024, 16, 16]           2,048\n            ReLU-129         [-1, 1024, 16, 16]               0\n      Bottleneck-130         [-1, 1024, 16, 16]               0\n          Conv2d-131          [-1, 256, 16, 16]         262,144\n     BatchNorm2d-132          [-1, 256, 16, 16]             512\n            ReLU-133          [-1, 256, 16, 16]               0\n          Conv2d-134          [-1, 256, 16, 16]         589,824\n     BatchNorm2d-135          [-1, 256, 16, 16]             512\n            ReLU-136          [-1, 256, 16, 16]               0\n          Conv2d-137         [-1, 1024, 16, 16]         262,144\n     BatchNorm2d-138         [-1, 1024, 16, 16]           2,048\n            ReLU-139         [-1, 1024, 16, 16]               0\n      Bottleneck-140         [-1, 1024, 16, 16]               0\n          Conv2d-141          [-1, 512, 16, 16]         524,288\n     BatchNorm2d-142          [-1, 512, 16, 16]           1,024\n            ReLU-143          [-1, 512, 16, 16]               0\n          Conv2d-144            [-1, 512, 8, 8]       2,359,296\n     BatchNorm2d-145            [-1, 512, 8, 8]           1,024\n            ReLU-146            [-1, 512, 8, 8]               0\n          Conv2d-147           [-1, 2048, 8, 8]       1,048,576\n     BatchNorm2d-148           [-1, 2048, 8, 8]           4,096\n          Conv2d-149           [-1, 2048, 8, 8]       2,097,152\n     BatchNorm2d-150           [-1, 2048, 8, 8]           4,096\n            ReLU-151           [-1, 2048, 8, 8]               0\n      Bottleneck-152           [-1, 2048, 8, 8]               0\n          Conv2d-153            [-1, 512, 8, 8]       1,048,576\n     BatchNorm2d-154            [-1, 512, 8, 8]           1,024\n            ReLU-155            [-1, 512, 8, 8]               0\n          Conv2d-156            [-1, 512, 8, 8]       2,359,296\n     BatchNorm2d-157            [-1, 512, 8, 8]           1,024\n            ReLU-158            [-1, 512, 8, 8]               0\n          Conv2d-159           [-1, 2048, 8, 8]       1,048,576\n     BatchNorm2d-160           [-1, 2048, 8, 8]           4,096\n            ReLU-161           [-1, 2048, 8, 8]               0\n      Bottleneck-162           [-1, 2048, 8, 8]               0\n          Conv2d-163            [-1, 512, 8, 8]       1,048,576\n     BatchNorm2d-164            [-1, 512, 8, 8]           1,024\n            ReLU-165            [-1, 512, 8, 8]               0\n          Conv2d-166            [-1, 512, 8, 8]       2,359,296\n     BatchNorm2d-167            [-1, 512, 8, 8]           1,024\n            ReLU-168            [-1, 512, 8, 8]               0\n          Conv2d-169           [-1, 2048, 8, 8]       1,048,576\n     BatchNorm2d-170           [-1, 2048, 8, 8]           4,096\n            ReLU-171           [-1, 2048, 8, 8]               0\n      Bottleneck-172           [-1, 2048, 8, 8]               0\n          Conv2d-173         [-1, 64, 128, 128]           9,408\n     BatchNorm2d-174         [-1, 64, 128, 128]             128\n            ReLU-175         [-1, 64, 128, 128]               0\n       MaxPool2d-176           [-1, 64, 64, 64]               0\n          Conv2d-177           [-1, 64, 64, 64]           4,096\n     BatchNorm2d-178           [-1, 64, 64, 64]             128\n            ReLU-179           [-1, 64, 64, 64]               0\n          Conv2d-180           [-1, 64, 64, 64]          36,864\n     BatchNorm2d-181           [-1, 64, 64, 64]             128\n            ReLU-182           [-1, 64, 64, 64]               0\n          Conv2d-183          [-1, 256, 64, 64]          16,384\n     BatchNorm2d-184          [-1, 256, 64, 64]             512\n          Conv2d-185          [-1, 256, 64, 64]          16,384\n     BatchNorm2d-186          [-1, 256, 64, 64]             512\n            ReLU-187          [-1, 256, 64, 64]               0\n      Bottleneck-188          [-1, 256, 64, 64]               0\n          Conv2d-189           [-1, 64, 64, 64]          16,384\n     BatchNorm2d-190           [-1, 64, 64, 64]             128\n            ReLU-191           [-1, 64, 64, 64]               0\n          Conv2d-192           [-1, 64, 64, 64]          36,864\n     BatchNorm2d-193           [-1, 64, 64, 64]             128\n            ReLU-194           [-1, 64, 64, 64]               0\n          Conv2d-195          [-1, 256, 64, 64]          16,384\n     BatchNorm2d-196          [-1, 256, 64, 64]             512\n            ReLU-197          [-1, 256, 64, 64]               0\n      Bottleneck-198          [-1, 256, 64, 64]               0\n          Conv2d-199           [-1, 64, 64, 64]          16,384\n     BatchNorm2d-200           [-1, 64, 64, 64]             128\n            ReLU-201           [-1, 64, 64, 64]               0\n          Conv2d-202           [-1, 64, 64, 64]          36,864\n     BatchNorm2d-203           [-1, 64, 64, 64]             128\n            ReLU-204           [-1, 64, 64, 64]               0\n          Conv2d-205          [-1, 256, 64, 64]          16,384\n     BatchNorm2d-206          [-1, 256, 64, 64]             512\n            ReLU-207          [-1, 256, 64, 64]               0\n      Bottleneck-208          [-1, 256, 64, 64]               0\n          Conv2d-209          [-1, 128, 64, 64]          32,768\n     BatchNorm2d-210          [-1, 128, 64, 64]             256\n            ReLU-211          [-1, 128, 64, 64]               0\n          Conv2d-212          [-1, 128, 32, 32]         147,456\n     BatchNorm2d-213          [-1, 128, 32, 32]             256\n            ReLU-214          [-1, 128, 32, 32]               0\n          Conv2d-215          [-1, 512, 32, 32]          65,536\n     BatchNorm2d-216          [-1, 512, 32, 32]           1,024\n          Conv2d-217          [-1, 512, 32, 32]         131,072\n     BatchNorm2d-218          [-1, 512, 32, 32]           1,024\n            ReLU-219          [-1, 512, 32, 32]               0\n      Bottleneck-220          [-1, 512, 32, 32]               0\n          Conv2d-221          [-1, 128, 32, 32]          65,536\n     BatchNorm2d-222          [-1, 128, 32, 32]             256\n            ReLU-223          [-1, 128, 32, 32]               0\n          Conv2d-224          [-1, 128, 32, 32]         147,456\n     BatchNorm2d-225          [-1, 128, 32, 32]             256\n            ReLU-226          [-1, 128, 32, 32]               0\n          Conv2d-227          [-1, 512, 32, 32]          65,536\n     BatchNorm2d-228          [-1, 512, 32, 32]           1,024\n            ReLU-229          [-1, 512, 32, 32]               0\n      Bottleneck-230          [-1, 512, 32, 32]               0\n          Conv2d-231          [-1, 128, 32, 32]          65,536\n     BatchNorm2d-232          [-1, 128, 32, 32]             256\n            ReLU-233          [-1, 128, 32, 32]               0\n          Conv2d-234          [-1, 128, 32, 32]         147,456\n     BatchNorm2d-235          [-1, 128, 32, 32]             256\n            ReLU-236          [-1, 128, 32, 32]               0\n          Conv2d-237          [-1, 512, 32, 32]          65,536\n     BatchNorm2d-238          [-1, 512, 32, 32]           1,024\n            ReLU-239          [-1, 512, 32, 32]               0\n      Bottleneck-240          [-1, 512, 32, 32]               0\n          Conv2d-241          [-1, 128, 32, 32]          65,536\n     BatchNorm2d-242          [-1, 128, 32, 32]             256\n            ReLU-243          [-1, 128, 32, 32]               0\n          Conv2d-244          [-1, 128, 32, 32]         147,456\n     BatchNorm2d-245          [-1, 128, 32, 32]             256\n            ReLU-246          [-1, 128, 32, 32]               0\n          Conv2d-247          [-1, 512, 32, 32]          65,536\n     BatchNorm2d-248          [-1, 512, 32, 32]           1,024\n            ReLU-249          [-1, 512, 32, 32]               0\n      Bottleneck-250          [-1, 512, 32, 32]               0\n          Conv2d-251          [-1, 256, 32, 32]         131,072\n     BatchNorm2d-252          [-1, 256, 32, 32]             512\n            ReLU-253          [-1, 256, 32, 32]               0\n          Conv2d-254          [-1, 256, 16, 16]         589,824\n     BatchNorm2d-255          [-1, 256, 16, 16]             512\n            ReLU-256          [-1, 256, 16, 16]               0\n          Conv2d-257         [-1, 1024, 16, 16]         262,144\n     BatchNorm2d-258         [-1, 1024, 16, 16]           2,048\n          Conv2d-259         [-1, 1024, 16, 16]         524,288\n     BatchNorm2d-260         [-1, 1024, 16, 16]           2,048\n            ReLU-261         [-1, 1024, 16, 16]               0\n      Bottleneck-262         [-1, 1024, 16, 16]               0\n          Conv2d-263          [-1, 256, 16, 16]         262,144\n     BatchNorm2d-264          [-1, 256, 16, 16]             512\n            ReLU-265          [-1, 256, 16, 16]               0\n          Conv2d-266          [-1, 256, 16, 16]         589,824\n     BatchNorm2d-267          [-1, 256, 16, 16]             512\n            ReLU-268          [-1, 256, 16, 16]               0\n          Conv2d-269         [-1, 1024, 16, 16]         262,144\n     BatchNorm2d-270         [-1, 1024, 16, 16]           2,048\n            ReLU-271         [-1, 1024, 16, 16]               0\n      Bottleneck-272         [-1, 1024, 16, 16]               0\n          Conv2d-273          [-1, 256, 16, 16]         262,144\n     BatchNorm2d-274          [-1, 256, 16, 16]             512\n            ReLU-275          [-1, 256, 16, 16]               0\n          Conv2d-276          [-1, 256, 16, 16]         589,824\n     BatchNorm2d-277          [-1, 256, 16, 16]             512\n            ReLU-278          [-1, 256, 16, 16]               0\n          Conv2d-279         [-1, 1024, 16, 16]         262,144\n     BatchNorm2d-280         [-1, 1024, 16, 16]           2,048\n            ReLU-281         [-1, 1024, 16, 16]               0\n      Bottleneck-282         [-1, 1024, 16, 16]               0\n          Conv2d-283          [-1, 256, 16, 16]         262,144\n     BatchNorm2d-284          [-1, 256, 16, 16]             512\n            ReLU-285          [-1, 256, 16, 16]               0\n          Conv2d-286          [-1, 256, 16, 16]         589,824\n     BatchNorm2d-287          [-1, 256, 16, 16]             512\n            ReLU-288          [-1, 256, 16, 16]               0\n          Conv2d-289         [-1, 1024, 16, 16]         262,144\n     BatchNorm2d-290         [-1, 1024, 16, 16]           2,048\n            ReLU-291         [-1, 1024, 16, 16]               0\n      Bottleneck-292         [-1, 1024, 16, 16]               0\n          Conv2d-293          [-1, 256, 16, 16]         262,144\n     BatchNorm2d-294          [-1, 256, 16, 16]             512\n            ReLU-295          [-1, 256, 16, 16]               0\n          Conv2d-296          [-1, 256, 16, 16]         589,824\n     BatchNorm2d-297          [-1, 256, 16, 16]             512\n            ReLU-298          [-1, 256, 16, 16]               0\n          Conv2d-299         [-1, 1024, 16, 16]         262,144\n     BatchNorm2d-300         [-1, 1024, 16, 16]           2,048\n            ReLU-301         [-1, 1024, 16, 16]               0\n      Bottleneck-302         [-1, 1024, 16, 16]               0\n          Conv2d-303          [-1, 256, 16, 16]         262,144\n     BatchNorm2d-304          [-1, 256, 16, 16]             512\n            ReLU-305          [-1, 256, 16, 16]               0\n          Conv2d-306          [-1, 256, 16, 16]         589,824\n     BatchNorm2d-307          [-1, 256, 16, 16]             512\n            ReLU-308          [-1, 256, 16, 16]               0\n          Conv2d-309         [-1, 1024, 16, 16]         262,144\n     BatchNorm2d-310         [-1, 1024, 16, 16]           2,048\n            ReLU-311         [-1, 1024, 16, 16]               0\n      Bottleneck-312         [-1, 1024, 16, 16]               0\n          Conv2d-313          [-1, 512, 16, 16]         524,288\n     BatchNorm2d-314          [-1, 512, 16, 16]           1,024\n            ReLU-315          [-1, 512, 16, 16]               0\n          Conv2d-316            [-1, 512, 8, 8]       2,359,296\n     BatchNorm2d-317            [-1, 512, 8, 8]           1,024\n            ReLU-318            [-1, 512, 8, 8]               0\n          Conv2d-319           [-1, 2048, 8, 8]       1,048,576\n     BatchNorm2d-320           [-1, 2048, 8, 8]           4,096\n          Conv2d-321           [-1, 2048, 8, 8]       2,097,152\n     BatchNorm2d-322           [-1, 2048, 8, 8]           4,096\n            ReLU-323           [-1, 2048, 8, 8]               0\n      Bottleneck-324           [-1, 2048, 8, 8]               0\n          Conv2d-325            [-1, 512, 8, 8]       1,048,576\n     BatchNorm2d-326            [-1, 512, 8, 8]           1,024\n            ReLU-327            [-1, 512, 8, 8]               0\n          Conv2d-328            [-1, 512, 8, 8]       2,359,296\n     BatchNorm2d-329            [-1, 512, 8, 8]           1,024\n            ReLU-330            [-1, 512, 8, 8]               0\n          Conv2d-331           [-1, 2048, 8, 8]       1,048,576\n     BatchNorm2d-332           [-1, 2048, 8, 8]           4,096\n            ReLU-333           [-1, 2048, 8, 8]               0\n      Bottleneck-334           [-1, 2048, 8, 8]               0\n          Conv2d-335            [-1, 512, 8, 8]       1,048,576\n     BatchNorm2d-336            [-1, 512, 8, 8]           1,024\n            ReLU-337            [-1, 512, 8, 8]               0\n          Conv2d-338            [-1, 512, 8, 8]       2,359,296\n     BatchNorm2d-339            [-1, 512, 8, 8]           1,024\n            ReLU-340            [-1, 512, 8, 8]               0\n          Conv2d-341           [-1, 2048, 8, 8]       1,048,576\n     BatchNorm2d-342           [-1, 2048, 8, 8]           4,096\n            ReLU-343           [-1, 2048, 8, 8]               0\n      Bottleneck-344           [-1, 2048, 8, 8]               0\n          Conv2d-345           [-1, 2048, 8, 8]      37,750,784\n     BatchNorm2d-346           [-1, 2048, 8, 8]           4,096\n            ReLU-347           [-1, 2048, 8, 8]               0\n       ConvBlock-348           [-1, 2048, 8, 8]               0\n          Conv2d-349           [-1, 2048, 8, 8]      37,750,784\n     BatchNorm2d-350           [-1, 2048, 8, 8]           4,096\n            ReLU-351           [-1, 2048, 8, 8]               0\n       ConvBlock-352           [-1, 2048, 8, 8]               0\n          Bridge-353           [-1, 2048, 8, 8]               0\n================================================================\nTotal params: 122,525,824\nTrainable params: 0\nNon-trainable params: 122,525,824\n----------------------------------------------------------------\nInput size (MB): 1.50\nForward/backward pass size (MB): 757.50\nParams size (MB): 467.40\nEstimated Total Size (MB): 1226.40\n----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (6,256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 256, 256])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.randn((6, 256, 256)).unsqueeze(0)\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 2048, 8, 8])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([131072])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "y.flatten().shape"
   ]
  }
 ]
}