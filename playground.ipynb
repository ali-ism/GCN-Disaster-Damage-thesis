{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from visualization import plot_on_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"datasets/xbd/tier3_bldgs/joplin-tornado/joplin-tornado_tier3_labels.csv\", index_col=0)\n",
    "plot_on_map(labels, color='zone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"datasets/xbd/tier3_bldgs/lower-puna-volcano/lower-puna-volcano_tier3_labels.csv\", index_col=0)\n",
    "plot_on_map(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polygon Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization import plot_image\n",
    "\n",
    "plot_image(\"datasets/xbd/tier3/labels/joplin-tornado_00000002_post_disaster.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization import plot_graph\n",
    "\n",
    "plot_graph('datasets/joplin-tornado_00000002.pt', 'datasets/joplin-tornado_00000002_post_disaster.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beirut Graph Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import BeirutFullGraph\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "dataset = BeirutFullGraph('datasets/beirut_bldgs/beirut_graph_meta', 'datasets/beirut_bldgs', 1366, meta_features=True)\n",
    "data = dataset[0]\n",
    "datax = to_networkx(data)\n",
    "pos = dict(enumerate(data.pos.numpy()))\n",
    "color_dict = {\n",
    "    0: (0, 1, 0),\n",
    "    1: (0, 0, 1),\n",
    "    2: (1, 0.27, 0),\n",
    "    3: (1, 0, 0)\n",
    "}\n",
    "colors = [color_dict[y] for y in data.y.numpy()]\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(35, 15)\n",
    "nx.draw_networkx(datax, pos=pos, arrows=False, with_labels=False, node_size=100, node_color=colors)\n",
    "custom_circles = [Circle((0,0), radius=0.2, color=(0, 1, 0)), Circle((0,0), radius=0.2, color=(0, 0, 1)),\n",
    "                  Circle((0,0), radius=0.2, color=(1, 0.27, 0)), Circle((0,0), radius=0.2, color=(1, 0, 0))]\n",
    "plt.legend(custom_circles, ['minor-damage', 'moderate-damage', 'major-damage', 'severe-damage'], prop={'size':15})\n",
    "plt.axis('off')\n",
    "#plt.savefig('beirut_graph.png', dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Clustering Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from train_autoencoder import _make_cost_m\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "cm = np.array([[46,26,475,26,11],[5,445,31,108,9],[4,506,32,54,1],[164,31,43,158,197],[408,12,6,15,123]])\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = linear_sum_assignment(_make_cost_m(cm))\n",
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm2 = cm[:, indexes[1]]\n",
    "cm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FP\n",
    "cm2.sum(axis=0) - np.diag(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FN\n",
    "cm2.sum(axis=1) - np.diag(cm2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Beirut Meta Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "cols = ['OID_', 'damage', 'Type', 'MIN_BLDG_N', 'MAX_BLDG_N', 'SUM_N_KWH', 'Shape_Leng', 'ORIG_FID', 'BUFF_DIST', 'ORIG_FID_1', 'Shape_Length', 'Shape_Area', 'Floors_fin', 'NbreEtages', 'Era_all', 'era_usj', 'Era_fin', 'era_usj_1']\n",
    "df = pd.read_csv('datasets/beirut_bldgs/buffered_masks.csv').drop(columns=cols)\n",
    "df['built_year_final'] = df.apply(lambda row: row['built_year'] if row['built_year'] else row['Annee'] , axis = 1)\n",
    "df['Floors_final'] = df.apply(lambda row: row['Floors'] if row['Floors'] else row['Estim_Etag'] , axis = 1)\n",
    "df.drop(columns=['built_year', 'Annee', 'Estim_Etag', 'Floors'], inplace=True)\n",
    "df.replace(r'\\s+', np.nan, regex=True, inplace=True)\n",
    "df['Const_Year'].fillna(0, inplace=True)\n",
    "df['Fonction'].fillna('Autre', inplace=True)\n",
    "#df = pd.get_dummies(df, drop_first=True)\n",
    "#num_cols = ['NbreAppts', 'MEAN_DSM_O', 'MEAN_Blg_H', 'Area', 'perimeter', 'era_final', 'built_year_final']\n",
    "#df[num_cols] = df[num_cols]/df[num_cols].max()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = df.drop(columns=['heritage','Fonction', 'Longitude', 'Latitude']).replace(0, np.nan).describe()\n",
    "stats.drop(index=['25%','50%','75%'], inplace=True)\n",
    "stats = stats.append(1366-stats.loc['count',:])\n",
    "stats.index = ['count', 'mean', 'std', 'min', 'max', 'number of nulls']\n",
    "stats.reindex(['count', 'number of nulls', 'mean', 'std', 'min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "df['heritage'].value_counts().plot(kind='bar', ylabel='Heritage', ax=ax1)\n",
    "df['Fonction'].replace({'Sante': 'Healthcare', 'Industrie': 'Industry', 'Religieux': 'Religion', 'Mixte': 'Mixed', 'Residentiel': 'Residential', 'Autre': 'Other'}).value_counts().plot(kind='bar', ylabel='Building Function', ax=ax2);\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import BeirutFullGraph\n",
    "\n",
    "dataset = BeirutFullGraph('datasets/beirut_bldgs/beirut_graph_meta', 'datasets/beirut_bldgs', 1366, True)\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('datasets/beirut_bldgs/beirut_graph_meta/processed/beirut_metadata.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Shannon Equitability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import shannon_equitability\n",
    "\n",
    "print(f'Joplin original: {shannon_equitability(np.array([8225, 2192, 1005, 3274])):.3f}')\n",
    "print(f'Joplin reduced: {shannon_equitability(np.array([649, 363, 243, 111])):.3f}')\n",
    "print()\n",
    "print(f'Pinery original: {shannon_equitability(np.array([5027, 82, 99, 229])):.3f}')\n",
    "print(f'Pinery reduced: {shannon_equitability(np.array([1100, 149, 64, 53])):.3f}')\n",
    "print()\n",
    "print(f'Nepal original: {shannon_equitability(np.array([31225, 5134, 4721, 502])):.3f}')\n",
    "print(f'Nepal reduced: {shannon_equitability(np.array([986, 189, 173, 18])):.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.arange(5) #['Pinery', 'Nepal', 'Joplin']\n",
    "y1 = [0.7145-0.4773, 0.4517-0.3439, 0.4941-0.3090, 0.7743-0.6651, 0.4646-0.3044] #pinery\n",
    "y2 = [0.7540-0.6179, 0.6987-0.5382, 0.6992-0.4967, 0.8778-0.7837, 0.6914-0.4967] #joplin\n",
    "y3 = [0.7086-0.5930, 0.5589-0.4056, 0.5199-0.4121, 0.7613-0.7059, 0.5328-0.4082]\n",
    "\n",
    "plt.bar(x-0.2, y1, 0.2, color='#f28e2b')\n",
    "plt.bar(x, y2, 0.2, color='#4e79a7')\n",
    "plt.bar(x+0.2, y3, 0.2, color='#e15759')\n",
    "plt.xticks(x, ['Accuracy', 'Precision', 'Recall', 'Specificity', 'F1'])\n",
    "plt.ylabel(\"Hold Score Differences\")\n",
    "plt.legend([\"Pinery\", \"Joplin\", \"Nepal\"])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.arange(4)\n",
    "acc = [0.911-0.887, 0.5092-0.6075, 0.7042-0.8542, 0.7094-0.8552]\n",
    "macro = [0.5642-0.5315, 0.3421-0.3275, 0.2824-0.3072, 0.2873-0.3131]\n",
    "weight = [0.9205-0.8902, 0.5487-0.6727, 0.587-0.7873, 0.5951-0.7899]\n",
    "auc = [0.9347-0.8374, 0.5314-0.4999, 0.5199-0.6445, 0.5394-0.6665]\n",
    "\n",
    "plt.bar(x-0.4, acc, 0.2, color='#f28e2b')\n",
    "plt.bar(x-0.2, macro, 0.2, color='#4e79a7')\n",
    "plt.bar(x, weight, 0.2, color='#e15759')\n",
    "plt.bar(x+0.2, auc, 0.2, color='#59a14f')\n",
    "plt.xticks(x, ['1', '2', '3', '4'])\n",
    "#plt.ylabel(\"Differences between Train and Hold Scores\")\n",
    "plt.legend([\"Accuracy\", \"Macro F1\", \"Weighted F1\", \"AUC\"])\n",
    "plt.axhline(color='black')\n",
    "plt.title('Graph SAGE')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.arange(4)\n",
    "acc = [0.8746-0.8531, 0.6921-0.4356, 0.9283-0.6082, 0.9666-0.6668]\n",
    "macro = [0.5994-0.5449, 0.6342-0.315, 0.9008-0.3913, 0.9522-0.4308]\n",
    "weight = [0.9036-0.8787, 0.7275-0.5708, 0.9306-0.6966, 0.9671-0.7405]\n",
    "auc = [0.9648-0.8609, 0.8764-0.6601, 0.9877-0.6597, 0.9963-0.6853]\n",
    "\n",
    "plt.bar(x-0.4, acc, 0.2, color='#f28e2b')\n",
    "plt.bar(x-0.2, macro, 0.2, color='#4e79a7')\n",
    "plt.bar(x, weight, 0.2, color='#e15759')\n",
    "plt.bar(x+0.2, auc, 0.2, color='#59a14f')\n",
    "plt.xticks(x, ['1', '2', '3', '4'])\n",
    "plt.ylabel(\"Differences between Train and Hold Scores\")\n",
    "#plt.legend([\"Accuracy\", \"Macro F1\", \"Weighted F1\", \"AUC\"])\n",
    "plt.axhline(color='black')\n",
    "plt.title('Siamese CNN')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74cf116ea1e63dd6a3edb90b75799d82a2f782fbf42bf6e53914daa55fad93a1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('torch-geo': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
