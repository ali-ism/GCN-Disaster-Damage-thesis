{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from feature_extractor import load_feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_feature_extractor()"
   ]
  },
  {
   "source": [
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = torch.zeros((3,256,256))\n",
    "x1 = torch.ones((3,256,256))\n",
    "x2 = 2*torch.ones((3,256,256))\n",
    "x3 = 3*torch.ones((3,256,256))\n",
    "x01 = torch.cat((x0, x1),0)\n",
    "x23 = torch.cat((x2, x3),0)\n",
    "y01 = model(x01.unsqueeze(0))\n",
    "y23 = model(x23.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y01.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x01.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.stack([x01,x23])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.all(y[0] == y01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.all(y[1] == y23)"
   ]
  },
  {
   "source": [
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = torch.zeros((3,256,256))\n",
    "x1 = torch.ones((3,256,256))\n",
    "x01 = torch.cat((x0, x1),0)\n",
    "y01 = model(x01.unsqueeze(0))\n",
    "\n",
    "def tensor_mem(x):\n",
    "    return x.element_size() * x.nelement() * 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizet = tensor_mem(y01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizet * 9573"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizet * 16874"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizet * 7630"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = {\n",
    "    'guatemala_train' : 1712 // 2,\n",
    "    'guatemala_test' : 64 // 2,\n",
    "    'guatemala_hold' : 206 // 2,\n",
    "    'florence_train' : 12892 // 2,\n",
    "    'florence_test' : 4536 // 2,\n",
    "    'florence_hold' : 5668 // 2,\n",
    "    'harvey_train' : 46028 // 2,\n",
    "    'harvey_test' : 15430 // 2,\n",
    "    'harvey_hold' : 14452 // 2,\n",
    "    'matthew_train' : 27878 // 2,\n",
    "    'matthew_test' : 8378 // 2,\n",
    "    'matthew_hold' : 11672 // 2,\n",
    "    'michael_train' : 45372 // 2,\n",
    "    'michael_test' : 11314 // 2,\n",
    "    'michael_hold' : 14316 // 2,\n",
    "    'mexico_train' : 65542 // 2,\n",
    "    'mexico_test' : 22822 // 2,\n",
    "    'mexico_hold' : 15582 // 2,\n",
    "    'midwest_train' : 17512 // 2,\n",
    "    'midwest_test' : 5064 // 2,\n",
    "    'midwest_hold' : 5216 // 2,\n",
    "    'palu_train' : 62788 // 2,\n",
    "    'palu_test' : 25120 // 2,\n",
    "    'palu_hold' : 23670 // 2,\n",
    "    'santa_train' : 25900 // 2,\n",
    "    'santa_test' : 8452 // 2,\n",
    "    'santa_hold' : 9558 // 2,\n",
    "    'socal_train' : 20950 // 2,\n",
    "    'socal_test' : 8544 // 2,\n",
    "    'socal_hold' : 8444 // 2\n",
    "}\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.bar(range(len(D)), list(D.values()), align='center');\n",
    "plt.xticks(range(len(D)), list(D.keys()), rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guatemala = D['guatemala_hold'] + D['guatemala_test'] + D['guatemala_train']\n",
    "sizet * guatemala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guatemala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "socal = D['socal_train'] + D['socal_test'] + D['socal_hold']\n",
    "sizet * socal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizet * D['mexico_train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "xbd_path = 'datasets/xbd'\n",
    "subsets = ('/train_bldgs/', '/hold_bldgs/', '/test_bldgs/', '/tier3_bldgs/')\n",
    "disaster_folders = os.listdir(xbd_path + subsets[0])\n",
    "\n",
    "i_subset = 0\n",
    "i_disaster = 0\n",
    "\n",
    "print(list(Path(xbd_path + subsets[i_subset] + disaster_folders[i_disaster]).glob('*.csv*'))[0])\n",
    "labels = pd.read_csv(list(Path(xbd_path + subsets[i_subset] + disaster_folders[i_disaster]).glob('*.csv*'))[0])\n",
    "labels.columns = ['name', 'xcoords', 'ycoords', 'long', 'lat', 'class']\n",
    "zone = lambda row: '_'.join(row['name'].split('_', 2)[:2])\n",
    "labels['zone'] = labels.apply(zone, axis=1)\n",
    "#labels['zone'].value_counts()\n",
    "#labels['zone'].value_counts()[labels['zone'].value_counts()==1].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization import plot_on_image\n",
    "\n",
    "plot_on_image(labels, subsets[i_subset], 'guatemala-volcano_00000000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization import plot_on_map\n",
    "\n",
    "plot_on_map(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from visualization import CmapString\n",
    "\n",
    "cmap = CmapString(palette='viridis', domain=labels['zone'].values)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "for _, row in labels.iterrows():\n",
    "    plt.scatter(row['xcoords'], row['ycoords'], label=row['zone'], color=cmap.color(row['zone']))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from generate_xbd_dirs import write_to_dict\n",
    "\n",
    "disaster_dict = defaultdict(list)\n",
    "xbd_path = 'datasets/xbd'\n",
    "subsets = ('/train_bldgs/', '/hold_bldgs/', '/test_bldgs/')\n",
    "disaster_folders = os.listdir(xbd_path + subsets[0])\n",
    "disaster_folders_tier3 = os.listdir(xbd_path + '/tier3_bldgs/')\n",
    "\n",
    "write_to_dict(disaster_dict, subsets[1], disaster_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(disaster_dict.keys())[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disaster_dict['guatemala-volcano_hold_pre_guatemala-volcano_00000020']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disaster_dict['guatemala-volcano_hold_post_guatemala-volcano_00000020']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([[0.8, 0.1, 0, 0],[0.7,0.6,0.3,0.2],[0.8,0.7,0.9,0.6]])\n",
    "\n",
    "idx = torch.where(a < 0.5, 1, 0)\n",
    "\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nz = torch.argmax(idx,dim=1)\n",
    "nz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.where(nz == 0, 4, nz)"
   ]
  },
  {
   "source": [
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "import torch\n",
    "import torchvision.transforms as tr\n",
    "from PIL import Image\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from feature_extractor import load_feature_extractor\n",
    "from utils import build_edge_idx, get_edge_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'datasets/xbd/train_bldgs/'\n",
    "disaster_folders = os.listdir(path)\n",
    "\n",
    "list_labels = []\n",
    "for disaster in disaster_folders:\n",
    "    labels = pd.read_csv(list(Path(path + disaster).glob('*.csv*'))[0], index_col=0)\n",
    "    labels.drop(columns=['long','lat'], inplace=True)\n",
    "    zone = lambda row: '_'.join(row.name.split('_', 2)[:2])\n",
    "    labels['zone'] = labels.apply(zone, axis=1)\n",
    "    list_labels.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_files = []\n",
    "for labels in list_labels:\n",
    "    zones = labels['zone'].value_counts()[labels['zone'].value_counts()>1].index.tolist()\n",
    "    for zone in zones:\n",
    "        processed_files.append(f'{zone}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2175"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "len(processed_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for disaster, labels in zip(disaster_folders, list_labels):\n",
    "    zones = labels['zone'].value_counts()[labels['zone'].value_counts()>1].index.tolist()\n",
    "    for zone in zones:\n",
    "        list_pre_images = list(map(str, Path(path + disaster).glob(f'{zone}_pre_disaster*')))\n",
    "        list_post_images = list(map(str, Path(path + disaster).glob(f'{zone}_post_disaster*')))\n",
    "        label = labels.loc[os.path.split(list_post_images[7])[1],'class']\n",
    "        break\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3810jvsc74a57bd095d70da30fd22c72e34c5b2686d9425669d156b01d561237a148d8f19599268b",
   "display_name": "Python 3.8.10 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}