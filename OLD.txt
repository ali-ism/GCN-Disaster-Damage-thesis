class SAGEConvWithEdges(torch.nn.Module):
    """
    This is an implementation of the GraphSage convolution that also takes into account edge features.
    Source:
        https://github.com/kkonevets/geo_detection/blob/9421a591123c380a1f232b6bff598cae8ff29a23/sage_conv.py
    """
    def __init__(self, in_channels, in_edge_channels, out_channels):
        super(SAGEConvWithEdges, self).__init__()

        self.node_mlp_rel = Linear(in_channels + in_edge_channels, out_channels)

    def forward(self, x, edge_index, edge_attr):
        row, col = edge_index
        x_row = x[row]

        edge_attr = torch.cat([x_row, edge_attr], 1)

        edge_attr = F.normalize(edge_attr)

        x = scatter(edge_attr, col, dim=0, dim_size=res_size, reduce='mean')
        x = self.node_mlp_rel(x)
        x = F.normalize(x)
        return x
    
    def reset_parameters(self):
        for l in self.modules():
            if type(l) == torch.nn.Linear:
                l.reset_parameters()

    def __repr__(self):
        return ' '.join(
            str([l.in_features, l.out_features]) for l in self.modules()
            if type(l) == torch.nn.Linear)

****************************************************************************************
****************************************************************************************

class IIDxBD(InMemoryDataset):
    def __init__(self,
                 root,
                 resnet_pretrained=False,
                 resnet_shared=False,
                 resnet_diff=True,
                 transform=None,
                 pre_transform=None) -> None:
        
        self.resnet_pretrained = resnet_pretrained
        self.resnet_shared = resnet_shared
        self.resnet_diff = resnet_diff
        self.xbd_path = xbd_path

        super(IIDxBD, self).__init__(root, transform, pre_transform)

        self.data, self.slices = torch.load(self.processed_paths[0])

    @property
    def raw_file_names(self) -> List:
        return []

    @property
    def processed_file_names(self) -> List[str]:
        return ['iid_data.pt']

    def download(self) -> None:
        pass

    def process(self):
        resnet50 = load_feature_extractor(self.resnet_pretrained, self.resnet_shared, self.resnet_diff)
        resnet50 = resnet50.to(device)
        disaster_folders = os.listdir(self.xbd_path + '/train_bldgs/')

        data_list = []
        self.annot_list = []

        for disaster in disaster_folders:
            x = []
            y = []
            coords = []
            split = []

            list_pre_images = disasters_dict[disaster + '_pre']
            list_post_images = disasters_dict[disaster + '_post']

            annotation_train = pd.read_csv(disasters_dict[disaster + '_labels'][0], index_col=0)
            annotation_train['split'] = ['train'] * annotation_train.shape[0]
            annotation_hold = pd.read_csv(disasters_dict[disaster + '_labels'][1], index_col=0)
            annotation_hold['split'] = ['hold'] * annotation_hold.shape[0]
            annotation_test = pd.read_csv(disasters_dict[disaster + '_labels'][2], index_col=0)
            annotation_test['split'] = ['test'] * annotation_test.shape[0]
            annotation = pd.concat((annotation_train, annotation_hold, annotation_test))
            self.annot_list.append(annotation.drop(annotation[annotation['class']=='un-classified'].index))

            pbar = tqdm(total=len(list_post_images))
            pbar.set_description(f'Building {disaster}, node features')

            for pre_image_file, post_image_file in zip(list_pre_images, list_post_images):
                if annotation.loc[os.path.split(post_image_file)[1],'class'] == 'un-classified':
                    continue

                #ordinal encoding of labels
                label = annotation.loc[os.path.split(post_image_file)[1],'class']
                if label == 'no-damage':
                    y.append([1,0,0,0])
                elif label == 'minor-damage':
                    y.append([1,1,0,0])
                elif label == 'major-damage':
                    y.append([1,1,1,0])
                elif label == 'destroyed':
                    y.append([1,1,1,1])
                else:
                    raise ValueError(f'Label class {label} undefined.')

                coords.append(annotation.loc[os.path.split(post_image_file)[1],'coords'])
                split.append(annotation.loc[os.path.split(post_image_file)[1],'split'])

                pre_image = Image.open(pre_image_file)
                post_image = Image.open(post_image_file)
                pre_image = pre_image.resize((256, 256))
                post_image = post_image.resize((256, 256))
                pre_image = transform(pre_image)
                post_image = transform(post_image)
                images = torch.cat((pre_image, post_image),0)
                x.append(images)
                pbar.update()
            
            pbar.close()
            x = torch.stack(x)
            x = x.to(device)
            with torch.no_grad():
                x = resnet50(x)
            x = x.detach().cpu()
            y = torch.tensor(y)

            #mask as train/val/test according to
            #https://stackoverflow.com/questions/65670777/loading-a-single-graph-into-a-pytorch-geometric-data-object-for-node-classificat
            train_mask = torch.zeros(x.shape[0])
            hold_mask = torch.zeros(x.shape[0])
            test_mask = torch.zeros(x.shape[0])

            split = pd.Series(split)
            train_mask[split[split=='train'].index] = 1
            hold_mask[split[split=='hold'].index] = 1
            test_mask[split[split=='test'].index] = 1

            train_mask = train_mask.type(torch.bool)
            hold_mask = hold_mask.type(torch.bool)
            test_mask = test_mask.type(torch.bool)

            #edge index matrix
            edge_index = build_edge_idx(x.shape[0])

            #edge features
            pbar = tqdm(total=edge_index.shape[1])
            pbar.set_description(f'Building {disaster}, edge features')
            
            edge_attr = torch.empty((edge_index.shape[1],2))
            for i in range(edge_index.shape[1]):
                node1 = x[edge_index[0,i]]
                node2 = x[edge_index[1,i]]
                coords1 = coords[edge_index[0,i]]
                coords2 = coords[edge_index[1,i]]
                attr = get_edge_weight(node1, node2, coords1, coords2)
                edge_attr[i,0] = attr[0]
                edge_attr[i,1] = attr[1]
                pbar.update()
            
            pbar.close()
            data_list.append(Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y,
                                  train_mask=train_mask, val_mask=test_mask, test_mask=hold_mask))


        if self.pre_filter is not None:
            data_list = [data for data in data_list if self.pre_filter(data)]

        if self.pre_transform is not None:
            data_list = [self.pre_transform(data) for data in data_list]

        data, slices = self.collate(data_list)
        torch.save((data, slices), self.processed_paths[0])